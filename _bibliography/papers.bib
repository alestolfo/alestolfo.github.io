---
---

@article{stolfo2022causal,
  abbr={arXiv},
  title="A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models",
  author={Stolfo*, Alessandro and Jin*, Zhijing and Shridhar, Kumar and Sch{\"o}lkopf, Bernhard and Sachan, Mrinmaya},
  journal={arXiv preprint},
  year={2022},
  selected={true},
  html={https://arxiv.org/abs/2210.12023}
}

@article{shridhar2022longtonotes,
  abbr={arXiv},
  title="Longtonotes: OntoNotes with Longer Coreference Chains",
  author={Shridhar, Kumar and Monath, Nicholas and Thirukovalluru, Raghuveer and Stolfo, Alessandro and Zaheer, Manzil and McCallum, Andrew and Sachan, Mrinmaya},
  journal={arXiv preprint},
  year={2022},
  selected={true},
  html={https://arxiv.org/abs/2210.03650}
}

@inproceedings{stolfo-etal-2022-simple,
    abbr={*SEM},
    title = "A Simple Unsupervised Approach for Coreference Resolution using Rule-based Weak Supervision",
    author = "Stolfo, Alessandro  and
      Tanner, Chris  and
      Gupta, Vikram  and
      Sachan, Mrinmaya",
    booktitle = "Proceedings of the 11th Joint Conference on Lexical and Computational Semantics,",
    month = jul,
    year = "2022",
    address = "Seattle, Washington",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.starsem-1.7",
    doi = "10.18653/v1/2022.starsem-1.7",
    pages = "79--88",
    abstract = "Labeled data for the task of Coreference Resolution is a scarce resource, requiring significant human effort. While state-of-the-art coreference models rely on such data, we propose an approach that leverages an end-to-end neural model in settings where labeled data is unavailable. Specifically, using weak supervision, we transfer the linguistic knowledge encoded by Stanford?s rule-based coreference system to the end-to-end model, which jointly learns rich, contextualized span representations and coreference chains. Our experiments on the English OntoNotes corpus demonstrate that our approach effectively benefits from the noisy coreference supervision, producing an improvement over Stanford?s rule-based system (+3.7 F1) and outperforming the previous best unsupervised model (+0.9 F1). Additionally, we validate the efficacy of our method on two other datasets: PreCo and Litbank (+2.5 and +5 F1 on Stanford{'}s system, respectively).",
    selected={true},
    url={https://aclanthology.org/2022.starsem-1.7/},
    html={https://aclanthology.org/2022.starsem-1.7/},
}

